{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from random import randint\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('news-headlines.csv', index_col=[\"Date\"], encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the count of 'Label' column from the dataset\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot(x='Label', data=df)\n",
    "plt.xlabel('Stock Sentiments (0-Down/Same, 1-Up)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN values\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup the database\n",
    "df_backup = df.copy()\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train an test set\n",
    "train = df[df['Date'] < '20150101']\n",
    "test = df[df['Date'] > '20141231']\n",
    "print('Train size: {}, Test size: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "y_train = train['Label']\n",
    "train = train.iloc[:, 3:28]\n",
    "y_test = test['Label']\n",
    "test = test.iloc[:, 3:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation and special character from the text\n",
    "train.replace(to_replace='[^a-zA-Z]', value=' ', regex=True, inplace=True)\n",
    "test.replace(to_replace='[^a-zA-Z]', value=' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "new_columns = [str(i) for i in range(0, 24)]\n",
    "train.columns = new_columns\n",
    "test.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the entire text to lower case\n",
    "for i in new_columns:\n",
    "    train[i] = train[i].str.lower()\n",
    "    test[i] = test[i].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all the columns\n",
    "train_headlines = []\n",
    "test_headlines = []\n",
    "\n",
    "for row in range(0, train.shape[0]):\n",
    "    train_headlines.append(' '.join(str(x) for x in train.iloc[row, 0:25]))\n",
    "\n",
    "for row in range(0, test.shape[0]):\n",
    "    test_headlines.append(' '.join(str(x) for x in test.iloc[row, 0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating corpus of train dataset\n",
    "ps = PorterStemmer()\n",
    "train_corpus = []\n",
    "\n",
    "for i in range(0, len(train_headlines)):\n",
    "    # Tokenizing the news-title by words\n",
    "    words = train_headlines[i].split()\n",
    "\n",
    "    # Removing the stopwords\n",
    "    words = [word for word in words if word not in set(\n",
    "        stopwords.words('english'))]\n",
    "\n",
    "    # Stemming the words\n",
    "    words = [ps.stem(word) for word in words]\n",
    "\n",
    "    # Joining the stemmed words\n",
    "    headline = ' '.join(words)\n",
    "\n",
    "    # Building a corpus of news-title\n",
    "    train_corpus.append(headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating corpus of test dataset\n",
    "test_corpus = []\n",
    "\n",
    "for i in range(0, len(test_headlines)):\n",
    "    # Tokenizing the news-title by words\n",
    "    words = test_headlines[i].split()\n",
    "\n",
    "    # Removing the stopwords\n",
    "    words = [word for word in words if word not in set(\n",
    "        stopwords.words('english'))]\n",
    "\n",
    "    # Stemming the words\n",
    "    words = [ps.stem(word) for word in words]\n",
    "\n",
    "    # Joining the stemmed words\n",
    "    headline = ' '.join(words)\n",
    "\n",
    "    # Building a corpus of news-title\n",
    "    test_corpus.append(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_words = []\n",
    "for i in list(y_train[y_train == 0].index):\n",
    "    down_words.append(train_corpus[i])\n",
    "\n",
    "up_words = []\n",
    "for i in list(y_train[y_train == 1].index):\n",
    "    up_words.append(train_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating wordcloud for down_words\n",
    "wordcloud1 = WordCloud(background_color='white', width=3000, height=2500).generate(down_words[1])\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wordcloud1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Words which indicate a fall in DJIA \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating wordcloud for up_words\n",
    "wordcloud2 = WordCloud(background_color='white', width=3000, height=2500).generate(up_words[5])\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wordcloud2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Words which indicate a rise in DJIA \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=10000, ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.fit_transform(train_corpus).toarray()\n",
    "X_test = cv.transform(test_corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_pred = lr_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "score1 = accuracy_score(y_test, lr_y_pred)\n",
    "score2 = precision_score(y_test, lr_y_pred)\n",
    "score3 = recall_score(y_test, lr_y_pred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm = confusion_matrix(y_test, lr_y_pred)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(data=lr_cm, annot=True, cmap=\"Blues\", xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Confusion Matrix for Logistic Regression Algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Precision and Recall\n",
    "score1 = accuracy_score(y_test, rf_y_pred)\n",
    "score2 = precision_score(y_test, rf_y_pred)\n",
    "score3 = recall_score(y_test, rf_y_pred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
    "rf_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(data=rf_cm, annot=True, cmap=\"Blues\", xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Confusion Matrix for Random Forest Algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 - Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "nb_y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, Precision and Recall\n",
    "score1 = accuracy_score(y_test, nb_y_pred)\n",
    "score2 = precision_score(y_test, nb_y_pred)\n",
    "score3 = recall_score(y_test, nb_y_pred)\n",
    "print(\"---- Scores ----\")\n",
    "print(\"Accuracy score is: {}%\".format(round(score1*100,2)))\n",
    "print(\"Precision score is: {}\".format(round(score2,2)))\n",
    "print(\"Recall score is: {}\".format(round(score3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "nb_cm = confusion_matrix(y_test, nb_y_pred)\n",
    "nb_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(data=nb_cm, annot=True, cmap=\"Blues\", xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Confusion Matrix for Multinomial Naive Bayes Algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_prediction(sample_news):\n",
    "    sample_news = re.sub(pattern='[^a-zA-Z]',repl=' ', string=sample_news)\n",
    "    sample_news = sample_news.lower()\n",
    "    sample_news_words = sample_news.split()\n",
    "    sample_news_words = [word for word in sample_news_words if not word in set(stopwords.words('english'))]\n",
    "    ps = PorterStemmer()\n",
    "    final_news = [ps.stem(word) for word in sample_news_words]\n",
    "    final_news = ' '.join(final_news)\n",
    "    temp = cv.transform([final_news]).toarray()\n",
    "    return lr_classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = df[df['Date'] > '20141231']\n",
    "sample_test.reset_index(inplace=True)\n",
    "sample_test = sample_test['Top1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values\n",
    "row = randint(0, sample_test.shape[0]-1)\n",
    "sample_news = sample_test[row]\n",
    "\n",
    "print('News: {}'.format(sample_news))\n",
    "if stock_prediction(sample_news):\n",
    "    print('Prediction: The stock price will remain the same or will go down.')\n",
    "else:\n",
    "    print('Prediction: The stock price will go up!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values\n",
    "row = randint(0,sample_test.shape[0]-1)\n",
    "sample_news = sample_test[row]\n",
    "\n",
    "print('News: {}'.format(sample_news))\n",
    "if stock_prediction(sample_news):\n",
    "    print('Prediction: The stock price will remain the same or will go down.')\n",
    "else:\n",
    "    print('Prediction: The stock price will go up!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values\n",
    "row = randint(0,sample_test.shape[0]-1)\n",
    "sample_news = sample_test[row]\n",
    "\n",
    "print('News: {}'.format(sample_news))\n",
    "if stock_prediction(sample_news):\n",
    "    print('Prediction: The stock price will remain the same or will go down.')\n",
    "else:\n",
    "    print('Prediction: The stock price will go up!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values\n",
    "row = randint(0, sample_test.shape[0]-1)\n",
    "sample_news = sample_test[row]\n",
    "\n",
    "print('News: {}'.format(sample_news))\n",
    "if stock_prediction(sample_news):\n",
    "    print('Prediction: The stock price will remain the same or will go down.')\n",
    "else:\n",
    "    print('Prediction: The stock price will go up!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
